{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgtRJ/JlQqtNrTKF6pvLP3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlaiclass/homework/blob/main/Ensemble_Learning_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this homework, you will solve the same problem from homework 1 using a different \n",
        "machine learning technique. Upload a .txt file with a link to your file as your submission on \n",
        "Submitty.**"
      ],
      "metadata": {
        "id": "gFuoXrnFakM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The machine learning problem that I solved in homework with\n",
        "Logistic Regression is predicting the risk of breast cancer. Logistic regression was a good choice for solving this problem because the dependent variable is binary (breast cancer exists or breast cancer does not exist. In this homework, I wil implement a decision tree classifier for my classification problem. \n"
      ],
      "metadata": {
        "id": "KeLGYgluaydE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1 (30 points): Implement a Decision Tree Classifier for your classification problem. You \n",
        "may use a built-in package to implement your classifier. Try modifying one or more of the input \n",
        "parameters and describe what changes you notice in your results. Clearly describe how these \n",
        "factors are affecting your output.** \"Decision Tree is a Supervised Machine Learning Algorithm that uses a set of rules to make decisions, similarly to how humans make decisions. One way to think of a Machine Learning classification algorithm is that it is built to make decisions. You usually say the model predicts the class of the new, never-seen-before input but, behind the scenes, the algorithm has to decide which class to assign.\""
      ],
      "metadata": {
        "id": "0ktP1SVMaxix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81UX4MZJfjVN"
      },
      "outputs": [],
      "source": [
        "# Import sklearn breast cancer data set that I used in my previous homework.\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "# This dataset includes detailed measurements for breast cancer recorded by the University of Wisconsin Hospitals.\n",
        "# Load breast_cancer data.\n",
        "breast_cancer = load_breast_cancer()\n",
        "# Create data frames.\n",
        "breast_cancer_df = pd.DataFrame(data= breast_cancer.data, columns= breast_cancer.feature_names)\n",
        "print(breast_cancer_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDnjx6RrSzHQ"
      },
      "outputs": [],
      "source": [
        "target_df = pd.DataFrame(data= breast_cancer.target, columns= ['species'])\n",
        "def converter(specie):\n",
        "    if specie == 0:\n",
        "        return 'radius'\n",
        "    elif specie == 1:\n",
        "        return 'diameter'\n",
        "    else:\n",
        "        return 'width'\n",
        "target_df['species'] = target_df['species'].apply(converter)\n",
        "\n",
        "# Concat the data frames.\n",
        "breast_cancer_df = pd.concat([breast_cancer_df, target_df], axis= 1)\n",
        "\n",
        "# View an overview of the dataset.\n",
        "breast_cancer_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wcfFvhfmplg"
      },
      "outputs": [],
      "source": [
        "# View dataset info.\n",
        "breast_cancer_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all of the required libraries.\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use scikit-learn's metrics module to calculate accuracy\n",
        "from sklearn import metrics \n",
        "\n",
        "col_names = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean concavity', 'concave points', 'mean symmetry', 'worst radius']\n",
        "breast_cancer_df.head() # Load our dataset from the previous homework.\n",
        "\n",
        "# Split our dataset into features.\n",
        "feature_cols = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean concavity', 'concave points', 'mean symmetry', 'worst radius']\n",
        "y = breast_cancer_df.label # These are our features.\n",
        "X = breast_cancer_df[feature_cols]\n",
        "\n",
        "# Split the dataset. I split the datset into 2: training set and test set.\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.35, random_state=1) # Use 35% of the data to test the model\n",
        "\n",
        "# Create a decision tree classifer.\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Train a decision tree classifier on the breast cancer data.\n",
        "decision_tree = decision_tree.fit(Xtrain,Ytrain)\n",
        "\n",
        "# Predict the results in our test data set which is 35% of the total training data.\n",
        "Ypred = decision_tree.predict(Xtest)\n",
        "\n",
        "# Compute the accuracy of the model.\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Ytest, Ypred))"
      ],
      "metadata": {
        "id": "4vbb03y8arLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 (30 points): From the Bagging and Boosting ensemble methods pick any one algorithm \n",
        "from each category. Implement both the algorithms using the same data. Use k-fold cross \n",
        "validation to find the effectiveness of both the models. Comment on the difference/similarity of \n",
        "the results.**"
      ],
      "metadata": {
        "id": "Vj5SN1wJaclh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Bagging ensemble method, I picked the [algorithm] to implement for the homework. \"Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once.\""
      ],
      "metadata": {
        "id": "XWYqxi8mnJuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries required for our bagging algorithm.\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Define our model.\n",
        "bagging_model = BaggingClassifier()\n",
        "\n",
        "# Evaluate our model for its accuracy.\n",
        "N = cross_val_score(bagging_model, X, y, scoring='accuracy', cv=C, n_jobs=-1, error_score='raise')\n",
        "C = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# Predict using bagging.\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Set our dataset.\n",
        "# We are using the same breast cancer data which is x and y.\n",
        "\n",
        "# Create the model.\n",
        "bagging_model = BaggingClassifier()\n",
        "\n",
        "# Fit our model to the entire breast cancer dataset.\n",
        "bagging_model.fit(X, y)"
      ],
      "metadata": {
        "id": "2HDvTbYFnZQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Boosting ensemble method, I picked the Extreme Gradient Boosting algorithm to implement for the homework. \"Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor.\""
      ],
      "metadata": {
        "id": "YikAlzDLnQgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from numpy import std\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Set our dataset.\n",
        "# We are using the same breast cancer data which is x and y.\n",
        "\n",
        "# Create model.\n",
        "boosting_model = XGBClassifier()\n",
        "\n",
        "# Evaluate our model.\n",
        "C = RepeatedStratifiedKFold(n_splits=10, random_state=1, n_repeats=3)\n",
        "N = cross_val_score(boosting_model, X, y,cv=C, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Print model's performance.\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(N), std(N)))\n",
        "\n",
        "# Create predictions using extreme boosting.\n",
        "from numpy import asarray\n",
        "from sklearn.datasets import make_classification\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define our model.\n",
        "boosting_model = XGBClassifier()\n",
        "\n",
        "# Fit our model to the entire dataset.\n",
        "boosting_model.fit(X, y)"
      ],
      "metadata": {
        "id": "t5U52NWinfPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used k-fold cross validation to find the effectiveness of both the models. \"K-fold cross-validation improves the model by validating the data. This technique ensures that the model’s score does not relate to the technique we use to choose the test or training dataset. K-fold cross-validationmethod divides the data set into subsets as K number.\""
      ],
      "metadata": {
        "id": "9ELQdnLGnZsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all of the required libraries.\n",
        "import model_selection module of scikit-learn\n",
        "from sklearn import \n",
        "\n",
        "# Set our dataset.\n",
        "# We are using the same breast cancer data which is x and y.\n",
        "\n",
        "# Use the model_selection model to initiate the k-fold class.\n",
        "k = model_selection.KFold(n_splits=8)\n",
        "\n",
        "# Use k-fold cross validation to find the effectiveness of the models.\n",
        "for fold, (trn_, val_) in enumerate(k.split(X=df)):\n",
        "df.loc[val_, 'kfold'] = fold"
      ],
      "metadata": {
        "id": "D1UJVwjOarqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3 (40 points): Compare the effectiveness of the three models implemented above. Clearly \n",
        "describe the metric you are using for comparison. Describe (with examples) Why is this \n",
        "metric(metrics) suited/appropriate for the problem at hand? How would a choice of a different \n",
        "metric impact your results? Can you demonstrate that?**"
      ],
      "metadata": {
        "id": "HR8tAMBKahJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will compare the effectiveness of the three models implemented above. I will clearly describe the metric I'm using for comparision to compare the effectiveness. The metric I'm using for comparison is recall. Recall evaluates the outcome of our algorithm for which the target/response value is a category. In practice recall compares the amount of values predicted correctly vs. not labeled correctly (definition learned from journaldev.com). This metric is suited and appropriate for the problem at hand beacuse it is especially relevant to our breast cancer dataset in which we want to concretely compare correct vs. incorrect choices. The choice of a different metric would impact my results by focusing on a different aspect of accuracy. This can be illustrated clearly in the difference in results between recall and precision. I can demonstrate that. I will demonstrate it bellow. The precision score is higher than the recall score."
      ],
      "metadata": {
        "id": "XOdkXLcUniKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "true_positive = np.diag(breast_cancer)\n",
        "false_negative = np.sum(breast_cancer, axis=1) - true_positive\n",
        "false_positive = np.sum(breast_cancer, axis=0) - true_positive\n",
        "\n",
        "# Set our dataset.\n",
        "# We are using the same breast cancer data which is x and y."
      ],
      "metadata": {
        "id": "hwDw5cLHjeoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, is the set up for the precision and recall metrics. We measure the number of true positives, false positives, and false negatives."
      ],
      "metadata": {
        "id": "zBLx98XMjfpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring precision. \n",
        "# Precision = True Positives / (True Positives + False Positives) \n",
        "# In the case of predicting cancer, it is important to not give a false diagnosis. \n",
        "precision = np.sum(true_positive / (true_positive + false_positive))\n",
        "print(precision)"
      ],
      "metadata": {
        "id": "y9aq0J_O_8LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring recall.\n",
        "# Recall simply measured how many true positives were identified.\n",
        "recall = np.sum(true_positive / (true_positive + false_negative))\n",
        "print(recall)"
      ],
      "metadata": {
        "id": "zyty-Hw5hYP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix may also be made. It is a visualization that allows us to see the performance of an ML algorithm. For the case of this model to predict breast cancer, recall is likely a better measure. Precision is important given it is important to not give a false diagnosis. However, it is likely more important to not miss a true positive. Therefore recall is a more important measure for this dataset."
      ],
      "metadata": {
        "id": "EBgaAw9CjxpK"
      }
    }
  ]
}